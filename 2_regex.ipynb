{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":70371,"databundleVersionId":7699046,"sourceType":"competition"}],"dockerImageVersionId":30646,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport re\nfrom itertools import zip_longest\n\n# ASSUMPTIONS\n# a.b. surname -> A.B. Surname\n# one-two-three ->  One-Two-Three or One-two-three ? (Instructions unclear)\n\n# LIMITATIONS\n# Cannot keep brackets in พระมหาอิษฎามาศ ปภสฺสรวณฺโณ (สุวรรณะ)\n# Cannot split 'มาริยา เถาอินปาก   ธีรชัย เนตรถนอมศักดิ์  เพ็ญณี  แนรอท' where no commas are used\n# Cannot split names with comma like Jose H. Bergantin, Jr.\n\npath = '/kaggle/input/thaijo-researcher-for-code-submission/test.csv'\nprefixes = ['Authors :', 'ม.ร.ว.', 'Assoc.Prof.Dr.', 'Assist. Prof. Dr.', 'Asst.Prof.Dr.', 'Mr.', 'M.L.', 'อาจารย์ ดร.', 'อ.ดร.', 'ผู้ช่วยศาสตราจารย์ ดร.', 'ผู้ช่วยศาสตราจารย์', 'รองศาสตราจารย์', 'ว่าที่ พ.ต. ดร.', 'ว่าที่ ร.ต.', 'ร.ต.อ.', 'พระครู', 'Phrakru', 'พระมหา', 'พันเอก', 'รองศาสตราจารย์ ดร.', 'รศ.', 'พระ', 'อาจารย์', 'ดร.', 'ผศ.ดร.', 'รศ.ดร.', 'Dr.',  'กสทช.', 'ครู']\nsuffixes = ['M.D.', 'M.R.', 'Ph.D', 'และคณะ', 'And Other', 'et al', 'et.al', 'Jr.', 'B. Pharm.', 'M. Pharm.', 'ดร.']\nfail_words = ['บรรณาธิการ', 'สารบัญ', 'committee', 'editorial', 'Cover Vol.', 'Journal', 'ผู้ทรงคุณวุฒิ', 'ผู้เขียน', 'โรงพยาบาล', 'วิทยาลัย', 'วารสาร', 'Cover Vol.', 'Thailand', 'Author ']\n\ndef detect_language(text: str) -> str:\n    thai_range = (0x0E01, 0x0E5B)  # Thai Unicode range\n    # arabic_range = (0x0600, 0x06FF)\n\n    num_thai = sum(thai_range[0] <= ord(char) <= thai_range[1] for char in text)\n    num_english = len(re.findall('[a-zA-ZàâçéèêëîïôùûüÿæœÀÂÇÉÈÊËÎÏÔÙÛÜŸÆŒ]', text))\n\n    is_thai = num_thai > 0\n    is_english = num_english > 0\n\n    if all((is_thai, is_english)):\n        return \"Thai and English\"\n    if is_thai:\n        return \"Thai\"\n    if is_english:\n        return \"English\"\n    else:\n        return None\n    \ndef extract_thai(text: str) -> str:\n    return ''.join(re.findall(r'[\\u0E01-\\u0E5B .,]', text))\n\ndef extract_eng(text: str) -> str:\n    return ''.join(re.findall('[a-zA-ZàâçéèêëîïôùûüÿæœÀÂÇÉÈÊËÎÏÔÙÛÜŸÆŒ .,-]', text))\n\ndef title_case(text: str) -> str:\n    # Instructions on required cases weren't clear, so tried a multiple\n    if not bool(text):\n        return ''\n    to_join = []\n    words = text.split(' ')\n    for word in words:\n        if not word:\n            continue\n        # ABcD -> abcd\n        word = word.lower()\n        # abcd -> Abcd\n        word = word[0].upper() + word[1:]\n#         word = word.title()\n        to_join.append(word)\n\n    res = ' '.join(to_join)    \n    # a.a. -> A.a.\n    res = re.sub(r'(?=\\s)[a-z]{1}\\.', lambda x: x.group(0).upper(), res)\n    # a.a -> a.A\n    res = re.sub(r'\\.{1}[a-z]{1}\\s', lambda x: x.group(0).upper(), res)\n    # a.a\\s -> a.A\\s\n    res = re.sub(r'\\.{1}[a-z]{1}\\.{1}\\s', lambda x: x.group(0).upper(), res)\n    return res\n\n\ndef clean_sentence(text: str) -> str:\n    if not bool(text):\n        return ''\n    text = text.strip(' ')\n    text = re.sub(' +', ' ', text)\n    text = re.sub(',+', ',', text)\n    # Remove email addresses\n    text = re.sub('[a-zA-Z.]+@[a-zA-Z.]+', '', text)\n    # Remove language change fault typos\n    text = text.lstrip(\" ,.'๋์ื'\")\n    text = text.strip(' -–')\n    return text\n\ndef split_sentence(text: str) -> str|list[str]:\n    try:\n        return text.split(',')\n    except:\n        return text\n    \ndef remove_prefix_suffix(text: str) -> str:\n    # Cannot use str.removeprefix() or str.removesuffix() because it will need the case to change.\n    for prefix in prefixes:\n        if text.lower().startswith(prefix.lower()):\n            text = text[len(prefix):]\n    for suffix in suffixes:\n        if text.lower().endswith(suffix.lower()):\n            text = text[:-len(suffix)]\n    return text\n\ndef clean_eng(text: str) -> str:\n    text = remove_prefix_suffix(text)\n    text = extract_eng(text)\n    text = clean_sentence(text)\n    text = title_case(text)\n    return text\n\ndef clean_thai(text: str) -> str:\n    text = remove_prefix_suffix(text)\n    text = extract_thai(text)\n    text = clean_sentence(text)\n    return text\n\ndef clean_word(text: str) -> str:\n    text = clean_sentence(text)\n    language = detect_language(text)\n    if language is None:\n        return text\n    \n    if language == 'Thai and English':\n        # Thai or English comes first\n        two_names = []\n        # Remove irrelevant aprts before judging language order\n        text = remove_prefix_suffix(text)\n        # What comes first\n        match detect_language(text[:2]):\n            case 'Thai':\n                # Thai first\n                thai_text = clean_thai(text)\n                thai_text = extract_thai(thai_text)\n                thai_text = clean_thai(thai_text)\n                two_names.append(thai_text)\n                # Then English\n                eng_text = clean_eng(text)\n                eng_text = extract_eng(eng_text)\n                eng_text = clean_eng(eng_text)\n                two_names.append(eng_text)\n                return two_names\n\n            case 'English':\n                # English first\n                eng_text = clean_eng(text)\n                eng_text = extract_eng(eng_text)\n                eng_text = clean_eng(eng_text)\n                two_names.append(eng_text)\n                # Then Thai\n                thai_text = clean_thai(text)\n                thai_text = extract_thai(thai_text)\n                thai_text = clean_thai(thai_text)\n                two_names.append(thai_text)\n                return two_names\n\n        return text\n    \n    if language == 'English':\n        return clean_eng(text)\n\n    if language == 'Thai':\n        return clean_thai(text)\n\n    raise ValueError('Unknown language error')\n\ndef final_clean(text: str) -> str:\n    return re.sub(r' \\.', '', text).rstrip(',').replace('..', '')\n\ndef check_fail_words(text: str|list[str]) -> str:\n    if not bool(text):\n        return ''\n    \n    temp_text = text\n    if isinstance(temp_text, list):\n        temp_text = ' '.join(temp_text)\n    for word in fail_words:\n        if word.lower() in temp_text.lower():\n            return ''\n    return text\n\ndef append_names(name_list: list[str], authors: str|list[str]) -> list[str]:\n    res = []\n    if not bool(authors):\n        return []\n    if isinstance(authors, str):\n        authors = [authors]\n    for a in authors:\n        a = final_clean(a)\n        if a not in name_list:\n            res.append(a)\n    return res\n\ndef main():\n    \n    # bool(np.nan) is True -> creates problems\n    df = pd.read_csv(path).replace({np.nan: None})\n    entries = []\n    for _, row in df.iterrows():\n\n        keys = [f\"{row['_id']}_{i}\" for i in range(1,11)]\n        names = []\n\n        # Get author\n        author = row['_source.author']\n        author = check_fail_words(author)\n        author = clean_sentence(author)\n        author = clean_word(author)\n        names.extend(append_names(names, author))\n\n        # Get Co-authors\n        co_authors = row['_source.co-author']\n        co_authors = clean_sentence(co_authors)\n        for ca in co_authors.split(','):\n            ca = clean_word(ca)\n            ca = check_fail_words(ca)\n            names.extend(append_names(names, ca))\n\n        # If no names at all\n        if not any(names):\n            names = [None for _ in range(10)]\n\n        # Clip at length 10\n        if len(names) > 10:\n            names = names[:10]\n\n        # zip_longest will automatically add None\n        entry = list(zip_longest(keys, names))\n        assert len(entry) == 10\n\n        entries.extend(entry)\n\n    df = pd.DataFrame(entries)\n    df.columns = ['id', 'name']\n    df.to_csv('submission.csv', index=False)\n    \n\nif __name__ == '__main__':\n    main()","metadata":{"_uuid":"6f9a46d1-cb85-40bf-8598-f9aea6d56e77","_cell_guid":"46abf07f-3ed9-4a25-8903-a29c7d8619ef","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-02-11T08:23:28.987743Z","iopub.execute_input":"2024-02-11T08:23:28.988117Z","iopub.status.idle":"2024-02-11T08:23:31.157701Z","shell.execute_reply.started":"2024-02-11T08:23:28.988088Z","shell.execute_reply":"2024-02-11T08:23:31.156743Z"},"trusted":true},"execution_count":2,"outputs":[]}]}